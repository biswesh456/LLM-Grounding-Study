Fri Nov 24 10:53:38 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Quadro RTX 8000                Off | 00000000:3B:00.0 Off |                    0 |
| N/A   28C    P8              27W / 250W |     15MiB / 46080MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     34961      G   /usr/bin/X                                   14MiB |
+---------------------------------------------------------------------------------------+
OAR_JOBID=13215695
OAR_ARRAYID=13215695
OARDIR=/usr/lib/oar
SHELL=/bin/bash
OAR_WORKING_DIRECTORY=/home/bmohapat/github/LLM-Grounding-Study/code/Llama
TERM=unknown
PERL5LIB=/usr/lib/oar
CONDA_SHLVL=1
OARCONFFILE=/etc/oar/oar.conf
CONDA_PROMPT_MODIFIER=(base) 
OAR_USER=bmohapat
QTDIR=/usr/lib64/qt-3.3
QTINC=/usr/lib64/qt-3.3/include
QT_GRAPHICSSYSTEM_CHECKED=1
USER=bmohapat
OAR_WORKDIR=/home/bmohapat/github/LLM-Grounding-Study/code/Llama
CONDA_EXE=/home/bmohapat/anaconda3/bin/conda
OARUSER=oar
OAR_JOB_NAME=
OAR_KEY=1
OAR_NODE_FILE=/var/lib/oar/13215695
_CE_CONDA=
OAR_RESOURCE_PROPERTIES_FILE=/var/lib/oar/13215695_resources
PATH=/home/bmohapat/anaconda3/bin:/home/bmohapat/anaconda3/condabin:/usr/lib64/qt-3.3/bin:/usr/lib/oar/oardodo:/usr/lib/oar/oardodo:/usr/local/bin:/usr/bin
OAR_PROJECT_NAME=default
OAR_JOB_WALLTIME_SECONDS=1800
CONDA_PREFIX=/home/bmohapat/anaconda3
PWD=/home/bmohapat/github/LLM-Grounding-Study/code/Llama
OAR_STDERR=OAR.13215695.stderr
LANG=en_US.UTF-8
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/misc/opt/modulefiles
LOADEDMODULES=
_CE_M=
OAR_ARRAY_ID=13215695
HOME=/home/bmohapat
SHLVL=2
OAR_FILE_NODES=/var/lib/oar/13215695
SUDO_COMMAND=OAR
OAR_ARRAYINDEX=1
OARXAUTHLOCATION=/usr/bin/xauth
OAR_JOB_WALLTIME=0:30:0
LOGNAME=bmohapat
OAR_NODEFILE=/var/lib/oar/13215695
CONDA_PYTHON_EXE=/home/bmohapat/anaconda3/bin/python
CVS_RSH=ssh
QTLIB=/usr/lib64/qt-3.3/lib
SSH_CONNECTION=193.51.209.233 54590 193.51.209.114 6667
OAR_RESOURCE_FILE=/var/lib/oar/13215695
MODULESHOME=/usr/share/Modules
LESSOPEN=||/usr/bin/lesspipe.sh %s
CONDA_DEFAULT_ENV=base
OAR_STDOUT=OAR.13215695.stdout
OARDO_USER=oar
OAR_JOB_ID=13215695
OAR_CPUSET=/oar/bmohapat_13215695
OAR_O_WORKDIR=/home/bmohapat/github/LLM-Grounding-Study/code/Llama
OAR_ARRAY_INDEX=1
OARDO_UID=888
BASH_FUNC_module()=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/printenv
[2023-11-24 10:53:52,884] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10.2
True
Total :  1
0
Loading the tokenizer...
Loading the model...
LlamaConfig {
  "_name_or_path": "/home/bmohapat/pyllama_data/hf_weights/7B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 0,
  "rms_norm_eps": 1e-06,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.30.2",
  "use_cache": false,
  "vocab_size": 32000
}

Creating the dataset...
###############Repair###############
shape of data (20, 8)
created test dataset
create trainer
[2023-11-24 10:55:11,234] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-24 10:55:11,234] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-24 10:55:11,234] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
created trainer
creating dataset
created dataset
Parameter Offload: Total persistent parameters: 266240 in 65 params
